{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af46889f-4af8-49e7-ad56-320c4cdc26a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b354c649-d7cb-4ffc-8c11-7dfbcaa00a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_text(text):\n",
    "    \"\"\"\n",
    "        Preprocess Text\n",
    "    \"\"\"\n",
    "    text = unicodedata.normalize(\"NFKD\", text) # Normalize\n",
    "    text = '\\n'.join(text.splitlines()) # Let python take care of unicode break lines\n",
    "\n",
    "    # Convert to upper\n",
    "    text = text.upper() # Convert to upper\n",
    "\n",
    "    # Take care of breaklines & whitespaces combinations due to beautifulsoup parsing\n",
    "    text = re.sub(r'[ ]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ ]+', '\\n', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # To find MDA section, reformat item headers\n",
    "    text = text.replace('\\n.\\n','.\\n') # Move Period to beginning\n",
    "\n",
    "    text = text.replace('\\nI\\nTEM','\\nITEM')\n",
    "    text = text.replace('\\nITEM\\n','\\nITEM ')\n",
    "    text = text.replace('\\nITEM  ','\\nITEM ')\n",
    "\n",
    "    text = text.replace(':\\n','.\\n')\n",
    "\n",
    "    # Math symbols for clearer looks\n",
    "    text = text.replace('$\\n','$')\n",
    "    text = text.replace('\\n%','%')\n",
    "\n",
    "    # Reformat\n",
    "    text = text.replace('\\n','\\n\\n') # Reformat by additional breakline\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80056004-7ae2-45c6-a88c-e732816a5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent':\"AnthonyNing/1.0 (pn2189@nyu.edu; For educational purposes)\"}\n",
    "\n",
    "def download_txt(url, doc_perm, f_type):\n",
    "    \n",
    "    fname = '_'.join(url.split('/')[-2:])\n",
    "    fname, ext = os.path.splitext(fname)\n",
    "    text_path = os.path.join('./txt', str(doc_perm)+'-'+f_type+'.txt')\n",
    "    \n",
    "    if os.path.exists(text_path):\n",
    "        print(\"Already exists, skipping {}\".format(url))\n",
    "        \n",
    "    else:\n",
    "        print(\"Downloading & Parsing {}\".format(url))\n",
    "        \n",
    "        r = requests.get(url, headers=headers)\n",
    "        try:\n",
    "            # Parse html with Beautiful Soup\n",
    "            soup = BeautifulSoup( r.content, \"html.parser\" )\n",
    "            text = soup.get_text(\"\\n\")\n",
    "    \n",
    "            # Process Text\n",
    "            text = _process_text(text)\n",
    "            \n",
    "            # Write to file\n",
    "            with codecs.open(text_path,'w',encoding='utf-8') as fout:\n",
    "                fout.write(text)\n",
    "            return True\n",
    "        \n",
    "        except BaseException as e:\n",
    "            print(\"{} parsing failed: {}\".format(url,e))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a5f8a7-9840-452a-b573-76cec85e7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "sp_files = pd.read_excel('sp500_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7576a6f4-f9e2-49c2-86ce-f903e33af0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1048911/0000950170-23-071495.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1090872/0001090872-23-000020.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1341439/0000950170-23-069682.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1467373/0001467373-23-000403.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1596783/0001596783-23-000185.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1596783/0001596783-23-000186.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1601046/0001601046-23-000134.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1645590/0001645590-23-000117.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/16732/0000016732-23-000176.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/1730168/0001730168-23-000096.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/29534/0001558370-23-019576.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/315189/0001558370-23-019812.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/40704/0001193125-23-299930.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/47217/0000047217-23-000100.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/48465/0000048465-23-000083.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/56873/0001558370-23-019686.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/6951/0000006951-23-000041.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/701985/0000701985-23-000035.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/711404/0000711404-23-000072.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/723125/0000723125-23-000077.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/72331/0000072331-23-000242.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/723531/0000950170-23-072195.txt\n",
      "http://www.sec.gov/Archives/edgar/data/723531/0000950170-23-072195.txt parsing failed: The markup you provided was rejected by the parser. Trying a different parser or a different encoding may help.\n",
      "\n",
      "Original exception(s) from parser:\n",
      " unknown status keyword 'KLM7' in marked section\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/745732/0000745732-23-000072.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/764478/0000764478-23-000053.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/769397/0000769397-23-000193.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/833444/0000833444-23-000048.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/866787/0001558370-23-019871.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/883241/0000883241-23-000019.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/909832/0000909832-23-000065.txt\n",
      "Downloading & Parsing http://www.sec.gov/Archives/edgar/data/91419/0000091419-23-000143.txt\n"
     ]
    }
   ],
   "source": [
    "prefix = 'http://www.sec.gov/Archives'\n",
    "\n",
    "company_name = []\n",
    "tik_lst = []\n",
    "cik_lst = []\n",
    "per_lst = []\n",
    "time = []\n",
    "form = []\n",
    "file = []\n",
    "  \n",
    "for i in range(len(sp_files)):\n",
    "    \n",
    "    url = os.path.join(prefix, sp_files.loc[i, 'filename'])\n",
    "    success = download_txt(url, sp_files.loc[i, 'permno'], sp_files.loc[i, 'form_type'])\n",
    "    \n",
    "    if success:\n",
    "        company_name.append(sp_files.loc[i, 'company_name'])\n",
    "        tik_lst.append(sp_files.loc[i, 'ticker'])\n",
    "        cik_lst.append(sp_files.loc[i, 'cik'])\n",
    "        per_lst.append(sp_files.loc[i, 'permno'])\n",
    "        time.append(sp_files.loc[i, 'filed_date'])\n",
    "        form.append(sp_files.loc[i, 'form_type'])\n",
    "        file.append(sp_files.loc[i, 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626c4ca7-ba5a-4f1e-95ec-639d1d75e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe containing company information whose 10-K or 10-Q files have been successfully downloaded\n",
    "file_dict = {'form_type': form, 'company_name': company_name, 'permno': per_lst, \n",
    "             'ticker':tik_lst, 'cik': cik_lst, 'filed_date': time, 'filename': file}\n",
    "df = pd.DataFrame(file_dict)\n",
    "# Write data into csv format\n",
    "df.to_csv('sp500_test_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7edcc-0eb1-4d6d-8d3f-38f435790654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

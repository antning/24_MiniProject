{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6aea925-adca-41c1-9ebf-28e21d11c875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (4.5.0)\n",
      "Requirement already satisfied: urllib3~=1.26 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.26.19)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/anthony_ning/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389f6919-ad1b-4ab9-a720-7fcc5202225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cc5ce2-f9c6-4b4b-ba75-fa6efc8bc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "service = Service('/Users/anthony_ning/Downloads/chromedriver_mac_arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "driver_2 = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd8061a-082e-4c4a-8a50-28b2212f9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the webpage\n",
    "url = 'https://www.federalreserve.gov/newsevents/speeches.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0471984d-ed87-4eea-ae0b-e2ed1e8c10a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content did not change. Reached the last page.\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "speakers = []\n",
    "dates = []\n",
    "articles = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    speeches = soup.find_all('div', class_='row ng-scope')\n",
    "    \n",
    "    for speech in speeches[1:]:\n",
    "        article_paragraphs = ''\n",
    "        \n",
    "        # title of the speech\n",
    "        title = speech.find('a').get_text(strip=True)\n",
    "        titles.append(title)\n",
    "\n",
    "        # speaker of the speech\n",
    "        speaker = speech.find('p', class_='news__speaker ng-binding').get_text(strip=True)\n",
    "        speakers.append(speaker)\n",
    "\n",
    "        # date of the speech\n",
    "        date = speech.find('time').get_text(strip=True)\n",
    "        dates.append(date)\n",
    "        \n",
    "        # speech url\n",
    "        speech_url = 'https://www.federalreserve.gov' + speech.find('a')['href']\n",
    "        # fetch the webpage\n",
    "        driver_2.get(speech_url)\n",
    "        soup = BeautifulSoup(driver_2.page_source, 'html.parser')\n",
    "        # speech content\n",
    "        content = soup.find('div', class_='col-xs-12 col-sm-8 col-md-8')\n",
    "\n",
    "        if content.find('div', class_='col-xs-12 col-md-7 pull-right'):\n",
    "            content.find('div', class_='col-xs-12 col-md-7 pull-right').decompose()\n",
    "        \n",
    "        for paragraph in content.find_all('p'):\n",
    "            \n",
    "            # Check if the paragraph contains a <strong> tag with the word 'References'\n",
    "            if paragraph.find('strong') and paragraph.find('strong').get_text(strip=True) == 'References':\n",
    "                # Stop processing when the \"References\" section starts\n",
    "                break\n",
    "                \n",
    "            elif paragraph.find_all('a'):\n",
    "                for a in paragraph.find_all('a'):\n",
    "                    if a.get('title') and 'footnote' in a.get('title'):\n",
    "                        a.decompose()\n",
    "                        skip = False\n",
    "                    elif a.get('name') and 'fn' in a.get('name'):\n",
    "                        a.decompose()\n",
    "                        skip =True\n",
    "                if not skip:\n",
    "                    article_paragraphs += paragraph.get_text(strip=True)\n",
    "                    article_paragraphs += ' '\n",
    "                else:\n",
    "                    break\n",
    "            elif paragraph.find('div'):\n",
    "                continue\n",
    "            else:\n",
    "                article_paragraphs += paragraph.get_text(strip=True)\n",
    "                article_paragraphs += ' '\n",
    "\n",
    "        articles.append(article_paragraphs)\n",
    "            \n",
    "    # Handle the pagination by clicking \"Next\"\n",
    "    try:\n",
    "        # Save a hash of the current page content\n",
    "        page_hash_before = hashlib.md5(driver.page_source.encode('utf-8')).hexdigest()\n",
    "\n",
    "        # Try to locate and click the \"Next\" button\n",
    "        next_button = driver.find_element(By.XPATH, '//a[text()=\"Next\"]')\n",
    "        next_button.click()\n",
    "\n",
    "        # Wait for the page to update\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        # Save a hash of the new page content\n",
    "        page_hash_after = hashlib.md5(driver.page_source.encode('utf-8')).hexdigest()\n",
    "\n",
    "        # Check if the page content changed\n",
    "        if page_hash_before == page_hash_after:\n",
    "            print(\"Page content did not change. Reached the last page.\")\n",
    "            break  # Exit the loop if the page content hasn't changed\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        # No \"Next\" button found, assume we've reached the last page\n",
    "        print(\"No 'Next' button found. Exiting loop.\")\n",
    "        break\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle potential stale element issues\n",
    "        print(\"Stale element encountered. Exiting loop.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3007309a-a948-4d69-9be9-8820c1d878dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'title': titles, 'speaker': speakers, 'date': dates, 'article': articles}\n",
    "data = pd.DataFrame(dic)\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Filter rows where the year is greater than or equal to 2019\n",
    "data_filtered = data[data['date'].dt.year >= 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9efba2d6-516f-4188-bde4-8df0f160a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.to_csv('FED_speech.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1677b68-306a-4661-96ec-619e43e134ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
